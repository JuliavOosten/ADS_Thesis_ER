{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3RT_GoaLXkMk"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import nltk\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "38aDQerOXXuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27770"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file. \"DiGraph\" is telling to reading the data with node-node. \"nodetype\" will identify whether the node is number or string or any other type.\n",
    "\n",
    "g = nx.read_edgelist(\"cit-HepTh.txt\",create_using=nx.DiGraph(), nodetype = int)\n",
    "\n",
    "# check if the data has been read properly or not.\n",
    "\n",
    "nx.info(g)\n",
    "\n",
    "# count the number of nodes\n",
    "\n",
    "g.number_of_nodes()\n",
    "\n",
    "# number of self-nodes\n",
    "\n",
    "#g.selfloop_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(g, \"cit_hepth.edgelist\")\n",
    "# nx.write_gexf(g, \"cit-hepth.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the authors, abstracts etc\n",
    "rootdir = '/Users/juliavanoosten/Documents/Studie/Msc. Applied Data Science/ADS Thesis/cit-HepTh/cit-HepTh-abstracts'\n",
    "abstracts = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        #print(os.path.join(subdir, file))\n",
    "        path = os.path.join(subdir, file)\n",
    "        with open(path) as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                paper = re.search(r\"(?<=Paper:)(((.|\\n)*))(?=From:)\",lines).group(0)\n",
    "                #date = re.search(r\"(?<=Date:)(((.|\\n)*))(?=Title:)\",lines).group(0)\n",
    "                title = re.search(r\"(?<=Title:)(((.|\\n)*))(?=Authors:)\",lines).group(0)\n",
    "                authors = re.search(r\"(?<=Authors:)(((.|\\n)*))(?=Comments:)\",lines).group(0)\n",
    "                #comments = re.search(r\"(?<=Comments:)(((.|\\n)*))(?=\\\\{3,})\",lines).group(0)\n",
    "#                 article = {\"paper\":paper, \"date\":date,\"title\":title,\"authors\":authors,\"comments\":comments}\n",
    "                article = {\"paper\":paper,\"title\":title,\"authors\":authors}\n",
    "                abstracts.append(article.copy())\n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from abstracts\n",
    "df =  pd.DataFrame(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Cleaning\n",
    "# Remove newlines\n",
    "df = df.applymap(lambda x: str(x).replace(\"\\n\",\"\"))\n",
    "df[\"paper\"] = df[\"paper\"].apply(lambda x: str(x).replace(\"hep-th/\",\"\"))\n",
    "df[\"authors\"] = df[\"authors\"].apply(lambda x: re.sub('\\d', '', x))\n",
    "\n",
    "# Split multiple authors and create multiple columnns\n",
    "df[\"authors\"] = df[\"authors\"].apply(lambda x: re.split(\", | and \",x))\n",
    "author_df = pd.DataFrame(df[\"authors\"].values.tolist()).add_prefix('author_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23911</th>\n",
       "      <td>0208183</td>\n",
       "      <td>Generalized Bogoliubov Transformation for Con...</td>\n",
       "      <td>[ J.C. da Silva (,), F.C. Khanna (,), A. Matos...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13942</th>\n",
       "      <td>9706081</td>\n",
       "      <td>Geometry of dynamics and phase transitions in...</td>\n",
       "      <td>[ Lando Caiani (), Lapo Casetti (, ), Cecilia ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <td>0207082</td>\n",
       "      <td>Relativistic invariant Lie algebras for kinem...</td>\n",
       "      <td>[ V. V. Khruschev (), A. N. Leznov (, , ) (() ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22321</th>\n",
       "      <td>0207152</td>\n",
       "      <td>Boundary One-Point Functions, Scattering, and...</td>\n",
       "      <td>[ V.A. Fateev (, ), E. Onofri (, ) (() Laborat...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20809</th>\n",
       "      <td>9603139</td>\n",
       "      <td>Lie Algebras of Differential Operators and Pa...</td>\n",
       "      <td>[ Federico Finkel(), Artemio Gonzalez-Lopez(),...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           paper                                              title  \\\n",
       "23911   0208183    Generalized Bogoliubov Transformation for Con...   \n",
       "13942   9706081    Geometry of dynamics and phase transitions in...   \n",
       "21087   0207082    Relativistic invariant Lie algebras for kinem...   \n",
       "22321   0207152    Boundary One-Point Functions, Scattering, and...   \n",
       "20809   9603139    Lie Algebras of Differential Operators and Pa...   \n",
       "\n",
       "                                                 authors  num_authors  \n",
       "23911  [ J.C. da Silva (,), F.C. Khanna (,), A. Matos...           21  \n",
       "13942  [ Lando Caiani (), Lapo Casetti (, ), Cecilia ...           20  \n",
       "21087  [ V. V. Khruschev (), A. N. Leznov (, , ) (() ...           18  \n",
       "22321  [ V.A. Fateev (, ), E. Onofri (, ) (() Laborat...           17  \n",
       "20809  [ Federico Finkel(), Artemio Gonzalez-Lopez(),...           16  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the cause of 21 authors\n",
    "df[\"num_authors\"] = df[\"authors\"].apply(lambda x: len(x)).sort_values()\n",
    "df.sort_values(by=\"num_authors\",ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>author_0</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>author_3</th>\n",
       "      <th>author_4</th>\n",
       "      <th>author_5</th>\n",
       "      <th>...</th>\n",
       "      <th>author_11</th>\n",
       "      <th>author_12</th>\n",
       "      <th>author_13</th>\n",
       "      <th>author_14</th>\n",
       "      <th>author_15</th>\n",
       "      <th>author_16</th>\n",
       "      <th>author_17</th>\n",
       "      <th>author_18</th>\n",
       "      <th>author_19</th>\n",
       "      <th>author_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9301112</td>\n",
       "      <td>On Integrable c&lt;1 Open--Closed String Theory</td>\n",
       "      <td>[ Clifford V. Johnson ]</td>\n",
       "      <td>1</td>\n",
       "      <td>Clifford V. Johnson</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9303063</td>\n",
       "      <td>Schwinger Effect in String Theory</td>\n",
       "      <td>[ C.Bachas ]</td>\n",
       "      <td>1</td>\n",
       "      <td>C.Bachas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9308136</td>\n",
       "      <td>Proof of Jacobi identity in generalized quant...</td>\n",
       "      <td>[ S.L. Adler, G.V. Bhanot, J.D. Weckel ]</td>\n",
       "      <td>3</td>\n",
       "      <td>S.L. Adler</td>\n",
       "      <td>G.V. Bhanot</td>\n",
       "      <td>J.D. Weckel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9308122</td>\n",
       "      <td>Mirror Symmetry, Mirror Map and Applications ...</td>\n",
       "      <td>[ S. Hosono, A. Klemm, S. Theisen ]</td>\n",
       "      <td>3</td>\n",
       "      <td>S. Hosono</td>\n",
       "      <td>A. Klemm</td>\n",
       "      <td>S. Theisen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9303077</td>\n",
       "      <td>Abelian Anomalies in Nonlocal Regularization</td>\n",
       "      <td>[ M. A. Clayton, L. Demopoulos, J. W. Moffat ]</td>\n",
       "      <td>3</td>\n",
       "      <td>M. A. Clayton</td>\n",
       "      <td>L. Demopoulos</td>\n",
       "      <td>J. W. Moffat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper                                              title  \\\n",
       "0   9301112       On Integrable c<1 Open--Closed String Theory    \n",
       "1   9303063                  Schwinger Effect in String Theory    \n",
       "2   9308136    Proof of Jacobi identity in generalized quant...   \n",
       "3   9308122    Mirror Symmetry, Mirror Map and Applications ...   \n",
       "4   9303077       Abelian Anomalies in Nonlocal Regularization    \n",
       "\n",
       "                                          authors  num_authors  \\\n",
       "0                         [ Clifford V. Johnson ]            1   \n",
       "1                                    [ C.Bachas ]            1   \n",
       "2        [ S.L. Adler, G.V. Bhanot, J.D. Weckel ]            3   \n",
       "3             [ S. Hosono, A. Klemm, S. Theisen ]            3   \n",
       "4  [ M. A. Clayton, L. Demopoulos, J. W. Moffat ]            3   \n",
       "\n",
       "                author_0       author_1       author_2 author_3 author_4  \\\n",
       "0   Clifford V. Johnson            None           None     None     None   \n",
       "1              C.Bachas            None           None     None     None   \n",
       "2             S.L. Adler    G.V. Bhanot   J.D. Weckel      None     None   \n",
       "3              S. Hosono       A. Klemm    S. Theisen      None     None   \n",
       "4          M. A. Clayton  L. Demopoulos  J. W. Moffat      None     None   \n",
       "\n",
       "  author_5  ... author_11 author_12 author_13 author_14 author_15 author_16  \\\n",
       "0     None  ...      None      None      None      None      None      None   \n",
       "1     None  ...      None      None      None      None      None      None   \n",
       "2     None  ...      None      None      None      None      None      None   \n",
       "3     None  ...      None      None      None      None      None      None   \n",
       "4     None  ...      None      None      None      None      None      None   \n",
       "\n",
       "  author_17 author_18 author_19 author_20  \n",
       "0      None      None      None      None  \n",
       "1      None      None      None      None  \n",
       "2      None      None      None      None  \n",
       "3      None      None      None      None  \n",
       "4      None      None      None      None  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the author_df and the other one back together\n",
    "combined_df = pd.concat([df, author_df], axis=1)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     9441\n",
       "1     7312\n",
       "3     5298\n",
       "4     1989\n",
       "5      481\n",
       "6      238\n",
       "7       68\n",
       "8       33\n",
       "9       19\n",
       "11       8\n",
       "10       6\n",
       "12       3\n",
       "13       2\n",
       "16       2\n",
       "20       1\n",
       "18       1\n",
       "17       1\n",
       "21       1\n",
       "Name: num_authors, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many other outlier author formats are there\n",
    "# Leave them out?\n",
    "df[\"num_authors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique authors and put them in a list\n",
    "unique_authors = []\n",
    "for column,data in author_df.iteritems():\n",
    "    unique_authors.append(author_df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 55106 authors in the network of which 25466 are unique at first glance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Kiyokazu Nagatomo (Osaka   University) ',\n",
       " 'C. Ungarelli',\n",
       " ' A. Wipf',\n",
       " 'and Masaki Shigemori ',\n",
       " ' V. Fateev',\n",
       " 'Thomas Mohaupt',\n",
       " ' A. Giveon',\n",
       " ' Dietrich B\\\\\"odeker',\n",
       " ' J.M. Isidro ',\n",
       " ' S. Sethi ',\n",
       " 'C. D. Fosco',\n",
       " ' B. Kleihaus',\n",
       " 'Kumar Rao ',\n",
       " 'F. Rodenas ',\n",
       " ' RJ Cova ',\n",
       " 'Seok-Jin Kang',\n",
       " 'A. Jevicki',\n",
       " 'Anton   Rebhan ',\n",
       " ' Masao Jinzenji']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: add cleaning + STRIP\n",
    "unique_authors = list(set(np.concatenate(unique_authors).ravel().tolist()))\n",
    "\n",
    "print(\"We have\",sum(df[\"num_authors\"]),\"authors in the network of which\",len(unique_authors),\"are unique at first glance\")\n",
    "unique_authors[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nones, \"and\", university details and empty strings\n",
    "def clean_authors(unique_authors):\n",
    "\n",
    "    unique_authors = list(filter(None, unique_authors))\n",
    "    unique_authors = [elem.replace(\"and \",\"\") for elem in unique_authors]\n",
    "    unique_authors = [elem.lower().strip() for elem in unique_authors]\n",
    "    unique_authors = [re.sub(r'\\(([^\\)]+)\\)', '', elem) for elem in unique_authors]\n",
    "    return unique_authors\n",
    "\n",
    "unique_authors = clean_authors(unique_authors)\n",
    "# Create pairs\n",
    "# author_pairs = list(itertools.combinations(unique_authors, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(s):\n",
    "  \n",
    "    # split the string into a list \n",
    "    l = s.split()\n",
    "    new = \"\"\n",
    "  \n",
    "    try:\n",
    "        # traverse in the list \n",
    "        for i in range(len(l)-1):\n",
    "            s = l[i]\n",
    "\n",
    "            # adds the capital first character \n",
    "            new += (s[0].upper()+'. ')\n",
    "\n",
    "        # l[-1] gives last item of list l. We\n",
    "        # use title to print first character in\n",
    "        # capital.\n",
    "        new += l[-1].title()\n",
    "\n",
    "        return new\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get authors in universal format\n",
    "unique_authors_df = pd.DataFrame(unique_authors)\n",
    "unique_authors_df[\"initial_lastname\"] = unique_authors_df.applymap(lambda x: name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_df.rename(columns={0: \"full_name\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25464"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_authors_df[\"full_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>initial_lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiyokazu nagatomo</td>\n",
       "      <td>K. Nagatomo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c. ungarelli</td>\n",
       "      <td>C. Ungarelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. wipf</td>\n",
       "      <td>A. Wipf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masaki shigemori</td>\n",
       "      <td>M. Shigemori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v. fateev</td>\n",
       "      <td>V. Fateev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            full_name initial_lastname\n",
       "0  kiyokazu nagatomo       K. Nagatomo\n",
       "1        c. ungarelli     C. Ungarelli\n",
       "2             a. wipf          A. Wipf\n",
       "3    masaki shigemori     M. Shigemori\n",
       "4           v. fateev        V. Fateev"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper', 'title', 'authors', 'num_authors', 'author_0', 'author_1',\n",
       "       'author_2', 'author_3', 'author_4', 'author_5', 'author_6', 'author_7',\n",
       "       'author_8', 'author_9', 'author_10', 'author_11', 'author_12',\n",
       "       'author_13', 'author_14', 'author_15', 'author_16', 'author_17',\n",
       "       'author_18', 'author_19', 'author_20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_df['index_nr'] = range(0, len(unique_authors_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliavanoosten/anaconda3/envs/AppliedDS/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 19s, sys: 2.88 s, total: 6min 22s\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get the paper_ids to find out on which papers the unique authors have worked\n",
    "paper_ids = []\n",
    "combined_df_clean = combined_df.copy()\n",
    "\n",
    "combined_df_clean[\"authors\"] =combined_df_clean[\"authors\"].apply(lambda x: clean_authors(x))\n",
    "combined_df_clean[\"authors\"]= combined_df_clean[\"authors\"].apply(lambda x: \" \".join(x))\n",
    "combined_df_clean.head()\n",
    " \n",
    "    \n",
    "for author in unique_authors_df[\"full_name\"]:\n",
    "    try:\n",
    "        paper_ids.append(list(combined_df_clean[combined_df_clean[\"authors\"].str.contains(author)][\"paper\"]))\n",
    "    except:\n",
    "        paper_ids.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25464 25464\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_authors_df), len(paper_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_df[\"affiliated_papers\"] = paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>initial_lastname</th>\n",
       "      <th>index_nr</th>\n",
       "      <th>affiliated_papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiyokazu nagatomo</td>\n",
       "      <td>K. Nagatomo</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 9704060 ,  9706118 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c. ungarelli</td>\n",
       "      <td>C. Ungarelli</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 9710188 ,  9701146 ,  9707053 ,  9706221 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. wipf</td>\n",
       "      <td>A. Wipf</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 9308130 ,  9310085 ,  9306161 ,  9308067 ,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masaki shigemori</td>\n",
       "      <td>M. Shigemori</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 0110035 ,  0206080 ,  0304138 ,  0303104 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v. fateev</td>\n",
       "      <td>V. Fateev</td>\n",
       "      <td>4</td>\n",
       "      <td>[ 0001012 ,  9709034 ,  9702190 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            full_name initial_lastname  index_nr  \\\n",
       "0  kiyokazu nagatomo       K. Nagatomo         0   \n",
       "1        c. ungarelli     C. Ungarelli         1   \n",
       "2             a. wipf          A. Wipf         2   \n",
       "3    masaki shigemori     M. Shigemori         3   \n",
       "4           v. fateev        V. Fateev         4   \n",
       "\n",
       "                                   affiliated_papers  \n",
       "0                             [ 9704060 ,  9706118 ]  \n",
       "1       [ 9710188 ,  9701146 ,  9707053 ,  9706221 ]  \n",
       "2  [ 9308130 ,  9310085 ,  9306161 ,  9308067 ,  ...  \n",
       "3       [ 0110035 ,  0206080 ,  0304138 ,  0303104 ]  \n",
       "4                  [ 0001012 ,  9709034 ,  9702190 ]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = unique_authors_df[\"full_name\"]\n",
    "#print(words)\n",
    "words = [re.sub('[^\\-0-9a-zA-Z]+', ' ', word).lower() for word in words]\n",
    "words = [word.strip() for word in words]\n",
    "unique_authors_df[\"cleaned\"] = words\n",
    "unique_authors_df = unique_authors_df.loc[unique_authors_df[\"cleaned\"].str.len()>1]\n",
    "unique_authors_df.drop_duplicates(subset=['cleaned'], keep='last',inplace=True)\n",
    "words = list(unique_authors_df[\"cleaned\"])\n",
    "words = [word for word in words if len(word)>1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_shingles(sentence: str, k: int): # had to adjust for shorter names\n",
    "    shingles = []\n",
    "    if len(sentence) <= k:\n",
    "        shingles.append(sentence)\n",
    "    else:\n",
    "        for i in range(len(sentence) - k):\n",
    "            shingles.append(sentence[i:i+k])\n",
    "        \n",
    "    return set(shingles)\n",
    "\n",
    "def build_vocab(shingle_sets: list):\n",
    "    # convert list of shingle sets into single set\n",
    "    full_set = {item for set_ in shingle_sets for item in set_}\n",
    "    vocab = {}\n",
    "    for i, shingle in enumerate(list(full_set)):\n",
    "        vocab[shingle] = i\n",
    "    return vocab\n",
    "\n",
    "def one_hot(shingles: set, vocab: dict):\n",
    "    vec = np.zeros(len(vocab))\n",
    "    for shingle in shingles:\n",
    "        idx = vocab[shingle]\n",
    "        vec[idx] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14250, 7310)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3 # shingle size\n",
    "# build shingles\n",
    "shingles = []\n",
    "for word in words:\n",
    "    shingles.append(build_shingles(word,k))\n",
    "\n",
    "# build vocab\n",
    "vocab = build_vocab(shingles)\n",
    "\n",
    "# one-hot encode our shingles\n",
    "shingles_1hot = []\n",
    "for shingle_set in shingles:\n",
    "    shingles_1hot.append(one_hot(shingle_set,vocab))\n",
    "\n",
    "shingles_1hot = np.stack(shingles_1hot)\n",
    "shingles_1hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingles_1hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(shingles_1hot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_arr(vocab: dict, resolution: int):\n",
    "    length = len(vocab.keys())\n",
    "    arr = np.zeros((resolution, length))\n",
    "    for i in range(resolution):\n",
    "        permutation = np.random.permutation(len(vocab)) + 1\n",
    "        arr[i, :] = permutation.copy()\n",
    "    return arr.astype(int)\n",
    "\n",
    "def get_signature(minhash, vector):\n",
    "    # get index locations of every 1 value in vector\n",
    "    idx = list(np.nonzero(vector))\n",
    "    idx = idx[0]\n",
    "    # use index locations to pull only +ve positions in minhash\n",
    "    shingles = minhash[:, idx]\n",
    "    # find minimum value in each hash vector\n",
    "    signature = np.min(shingles, axis=1)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s khokhlachev {'kho', 'okh', 'khl', 'che', 'lac', ' kh', 'hla', 'ach', 'hok', 's k'}\n"
     ]
    }
   ],
   "source": [
    "print(words[844], shingles[844])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dietrich b odeker {'ch ', 'die', 'iet', 'b o', 'tri', 'etr', ' b ', 'dek', 'eke', 'ric', 'ich', ' od', 'ode', 'h b'}\n"
     ]
    }
   ],
   "source": [
    "print(words[1], shingles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14250, 40)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = minhash_arr(vocab, 40)\n",
    "\n",
    "signatures = []\n",
    "index = 0\n",
    "\n",
    "for vector in shingles_1hot:\n",
    "    try:\n",
    "        signatures.append(get_signature(arr, vector))\n",
    "    except:\n",
    "        print(vector, index) # put here to find the issue of empty vectors --> was caused by names >= than k-len\n",
    "    index += 1\n",
    "\n",
    "\n",
    "# merge signatures into single array\n",
    "signatures = np.stack(signatures)\n",
    "signatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12, 1551,   72,   72,  637, 1172,  320,  871,  646,  149,  884,\n",
       "        173,  378,  310,  610,  563,   18,    7,   52,  212,   71,  247,\n",
       "        102,   64,  696,   46,  298,  646,  178, 1508,  291,  105,   56,\n",
       "        440,  382,  213, 1837,  438,  405,  264])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "class LSH:\n",
    "    buckets = []\n",
    "    counter = 0\n",
    "    def __init__(self, b):\n",
    "        self.b = b\n",
    "        for i in range(b):\n",
    "            self.buckets.append({})\n",
    "\n",
    "    def make_subvecs(self, signature):\n",
    "        l = len(signature)\n",
    "        assert l % self.b == 0\n",
    "        r = int(l / self.b)\n",
    "        # break signature into subvectors\n",
    "        subvecs = []\n",
    "        for i in range(0, l, r):\n",
    "            subvecs.append(signature[i:i+r])\n",
    "        return np.stack(subvecs)\n",
    "\n",
    "    def add_hash(self, signature):\n",
    "        subvecs = self.make_subvecs(signature).astype(str)\n",
    "        for i, subvec in enumerate(subvecs):\n",
    "            subvec = ','.join(subvec)\n",
    "            if subvec not in self.buckets[i].keys():\n",
    "                self.buckets[i][subvec] = []\n",
    "            self.buckets[i][subvec].append(self.counter)\n",
    "        self.counter += 1\n",
    "\n",
    "    def check_candidates(self):\n",
    "        candidates = []\n",
    "        for bucket_band in self.buckets:\n",
    "            keys = bucket_band.keys()\n",
    "            for bucket in keys:\n",
    "                hits = bucket_band[bucket]\n",
    "                if len(hits) > 1:\n",
    "                    candidates.extend(combinations(hits, 2))\n",
    "        return set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 20\n",
    "\n",
    "lsh = LSH(b)\n",
    "\n",
    "for signature in signatures:\n",
    "    lsh.add_hash(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443751"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = lsh.check_candidates()\n",
    "len(candidate_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2538, 2974), (11168, 13088), (9723, 12853), (6228, 12350), (3358, 10461)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(candidate_pairs)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443751"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 622 ms, sys: 22.3 ms, total: 644 ms\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TO DO KEEP INDEXES\n",
    "\n",
    "# create pairs list converting hashed to names\n",
    "candidate_pairs_lsh = candidate_pairs\n",
    "candidate_pairs_names = []\n",
    "\n",
    "for index, tuple in enumerate(candidate_pairs_lsh):\n",
    "    word_index_1 = int(tuple[0])\n",
    "    word_index_2 = int(tuple[1])\n",
    "    candidate_pairs_names.append((words[word_index_1],words[word_index_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 1.28 s, total: 3min 6s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edit_distances = []\n",
    "\n",
    "\n",
    "# get edit distances score\n",
    "for index, tuple in enumerate(candidate_pairs_names):\n",
    "    edit_distances.append(nltk.edit_distance(tuple[0], tuple[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>khazret nirov</td>\n",
       "      <td>margaret e wessling</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>queen mary westfield</td>\n",
       "      <td>n dorey washington</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k imilkowska</td>\n",
       "      <td>jan sladkowski</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j d laenge</td>\n",
       "      <td>a d odintsov</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stefan antusch</td>\n",
       "      <td>brian j h</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443746</th>\n",
       "      <td>mikhail i dobroliubov</td>\n",
       "      <td>m k gaillard</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443747</th>\n",
       "      <td>shihao chen</td>\n",
       "      <td>takashi mishima</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443748</th>\n",
       "      <td>andrei marshakov</td>\n",
       "      <td>v c de andrade</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443749</th>\n",
       "      <td>r garavuso</td>\n",
       "      <td>alberto garcia</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443750</th>\n",
       "      <td>ivan j muzinich</td>\n",
       "      <td>j mannix uc</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  candidate_1          candidate_2  edit_dist\n",
       "0               khazret nirov  margaret e wessling         15\n",
       "1        queen mary westfield   n dorey washington         15\n",
       "2                k imilkowska       jan sladkowski          8\n",
       "3                  j d laenge         a d odintsov          8\n",
       "4              stefan antusch            brian j h         10\n",
       "...                       ...                  ...        ...\n",
       "443746  mikhail i dobroliubov         m k gaillard         16\n",
       "443747            shihao chen      takashi mishima         12\n",
       "443748       andrei marshakov       v c de andrade         13\n",
       "443749             r garavuso       alberto garcia         11\n",
       "443750        ivan j muzinich          j mannix uc         12\n",
       "\n",
       "[443751 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with candidate pairs dataframe\n",
    "cpn_df = pd.concat((pd.DataFrame(candidate_pairs_names,columns=[\"candidate_1\",\"candidate_2\"]),pd.DataFrame(edit_distances, columns=[\"edit_dist\"])),axis=1)\n",
    "cpn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151750</th>\n",
       "      <td>y kimura</td>\n",
       "      <td>t kimura</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360100</th>\n",
       "      <td>r h rietdijk</td>\n",
       "      <td>rh rietdijk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160577</th>\n",
       "      <td>p kosi nski</td>\n",
       "      <td>p kosinski</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100885</th>\n",
       "      <td>matthias braendle</td>\n",
       "      <td>matthias brandle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252761</th>\n",
       "      <td>s deger</td>\n",
       "      <td>s deser</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249994</th>\n",
       "      <td>s j rey</td>\n",
       "      <td>s -j rey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221584</th>\n",
       "      <td>g furlan</td>\n",
       "      <td>p furlan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93390</th>\n",
       "      <td>h kr o ger</td>\n",
       "      <td>h kr oger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43292</th>\n",
       "      <td>c lee</td>\n",
       "      <td>w lee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19920</th>\n",
       "      <td>t h ubsch</td>\n",
       "      <td>t hubsch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152382</th>\n",
       "      <td>yoichro matsumura</td>\n",
       "      <td>yoichiro matsumura</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133845</th>\n",
       "      <td>m b silva-neto</td>\n",
       "      <td>m b silva neto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309407</th>\n",
       "      <td>c lee</td>\n",
       "      <td>t lee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424603</th>\n",
       "      <td>f dolan</td>\n",
       "      <td>b dolan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341732</th>\n",
       "      <td>j sakamoto</td>\n",
       "      <td>m sakamoto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79422</th>\n",
       "      <td>c s lim</td>\n",
       "      <td>c s lam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324700</th>\n",
       "      <td>v j menon</td>\n",
       "      <td>m j menon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72440</th>\n",
       "      <td>i volovich</td>\n",
       "      <td>a volovich</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377369</th>\n",
       "      <td>c martin</td>\n",
       "      <td>j martin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359983</th>\n",
       "      <td>vitoria-es</td>\n",
       "      <td>vitoria es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283207</th>\n",
       "      <td>k konishi</td>\n",
       "      <td>y konishi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14491</th>\n",
       "      <td>h arod z</td>\n",
       "      <td>h arodz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329634</th>\n",
       "      <td>j m mourao</td>\n",
       "      <td>j m mour ao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424607</th>\n",
       "      <td>s alexandrov</td>\n",
       "      <td>a alexandrov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347674</th>\n",
       "      <td>yoon-bai kim</td>\n",
       "      <td>yoonbai kim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325576</th>\n",
       "      <td>joan sim o n</td>\n",
       "      <td>joan sim on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412417</th>\n",
       "      <td>m sato</td>\n",
       "      <td>t sato</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265236</th>\n",
       "      <td>a c davis</td>\n",
       "      <td>a -c davis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56870</th>\n",
       "      <td>d polyakov</td>\n",
       "      <td>a polyakov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30094</th>\n",
       "      <td>s lee</td>\n",
       "      <td>w lee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              candidate_1         candidate_2  edit_dist\n",
       "151750           y kimura            t kimura          1\n",
       "360100       r h rietdijk         rh rietdijk          1\n",
       "160577        p kosi nski          p kosinski          1\n",
       "100885  matthias braendle    matthias brandle          1\n",
       "252761            s deger             s deser          1\n",
       "249994            s j rey            s -j rey          1\n",
       "221584           g furlan            p furlan          1\n",
       "93390          h kr o ger           h kr oger          1\n",
       "43292               c lee               w lee          1\n",
       "19920           t h ubsch            t hubsch          1\n",
       "152382  yoichro matsumura  yoichiro matsumura          1\n",
       "133845     m b silva-neto      m b silva neto          1\n",
       "309407              c lee               t lee          1\n",
       "424603            f dolan             b dolan          1\n",
       "341732         j sakamoto          m sakamoto          1\n",
       "79422             c s lim             c s lam          1\n",
       "324700          v j menon           m j menon          1\n",
       "72440          i volovich          a volovich          1\n",
       "377369           c martin            j martin          1\n",
       "359983         vitoria-es          vitoria es          1\n",
       "283207          k konishi           y konishi          1\n",
       "14491            h arod z             h arodz          1\n",
       "329634         j m mourao         j m mour ao          1\n",
       "424607       s alexandrov        a alexandrov          1\n",
       "347674       yoon-bai kim         yoonbai kim          1\n",
       "325576       joan sim o n         joan sim on          1\n",
       "412417             m sato              t sato          1\n",
       "265236          a c davis          a -c davis          1\n",
       "56870          d polyakov          a polyakov          1\n",
       "30094               s lee               w lee          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some checks\n",
    "cpn_df= cpn_df[cpn_df[\"edit_dist\"]>0]\n",
    "cpn_df.sort_values(by=[\"edit_dist\"],ascending=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(cpn_df[\"candidate_1\"].str.strip() == cpn_df[\"candidate_2\"].str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>a p veselov</td>\n",
       "      <td>a i veselov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>s-y pi</td>\n",
       "      <td>s -y pi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>h c lee</td>\n",
       "      <td>h w lee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>j meyer</td>\n",
       "      <td>h meyer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>e hernandez</td>\n",
       "      <td>r hernandez</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441031</th>\n",
       "      <td>g nagao</td>\n",
       "      <td>t nagao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441241</th>\n",
       "      <td>a takahashi</td>\n",
       "      <td>h takahashi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441268</th>\n",
       "      <td>ulf lindstr om</td>\n",
       "      <td>ulf lindstr o m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441906</th>\n",
       "      <td>m z iofa nuclear physics institute</td>\n",
       "      <td>m z iofa nuclear physics intitute</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441986</th>\n",
       "      <td>zbigniew jask olski</td>\n",
       "      <td>zbigniew jaskolski</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               candidate_1                        candidate_2  \\\n",
       "390                            a p veselov                        a i veselov   \n",
       "2791                                s-y pi                            s -y pi   \n",
       "3595                               h c lee                            h w lee   \n",
       "4091                               j meyer                            h meyer   \n",
       "4272                           e hernandez                        r hernandez   \n",
       "...                                    ...                                ...   \n",
       "441031                             g nagao                            t nagao   \n",
       "441241                         a takahashi                        h takahashi   \n",
       "441268                      ulf lindstr om                    ulf lindstr o m   \n",
       "441906  m z iofa nuclear physics institute  m z iofa nuclear physics intitute   \n",
       "441986                 zbigniew jask olski                 zbigniew jaskolski   \n",
       "\n",
       "        edit_dist  \n",
       "390             1  \n",
       "2791            1  \n",
       "3595            1  \n",
       "4091            1  \n",
       "4272            1  \n",
       "...           ...  \n",
       "441031          1  \n",
       "441241          1  \n",
       "441268          1  \n",
       "441906          1  \n",
       "441986          1  \n",
       "\n",
       "[720 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn_df[cpn_df[\"edit_dist\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio(\"tom tom howard\",\"tom howard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_sort_ratio(\"tom tom howard\",\"tom howard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio(\"o lebedev\",\"d lebedev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 s, sys: 182 ms, total: 19.9 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fuzzy_score = []\n",
    "\n",
    "# calculate fuzzy scores, facilitating different order in sequence\n",
    "for index, tuple in enumerate(candidate_pairs_names):\n",
    "    fuzzy_score.append((fuzz.token_sort_ratio(tuple[0], tuple[1])+fuzz.token_set_ratio(tuple[0], tuple[1]))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpn_df = pd.concat((cpn_df,pd.DataFrame(fuzzy_score, columns=[\"fuzzy_score\"])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliavanoosten/anaconda3/envs/AppliedDS/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "      <th>fuzzy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441906</th>\n",
       "      <td>m z iofa nuclear physics institute</td>\n",
       "      <td>m z iofa nuclear physics intitute</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>st a ephane ouvry division de physique th eorique</td>\n",
       "      <td>st ephane ouvry division de physique th eorique</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359242</th>\n",
       "      <td>sergei m kuzenko institut fuer theoretische ph...</td>\n",
       "      <td>sergei kuzenko institut fuer theoretische physik</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422225</th>\n",
       "      <td>norma manko v c bor v s tnik</td>\n",
       "      <td>norma manko v c bor v stnik</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397049</th>\n",
       "      <td>m semenov-tian-shansky</td>\n",
       "      <td>m a semenov-tian-shansky</td>\n",
       "      <td>2</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388590</th>\n",
       "      <td>m khlopov</td>\n",
       "      <td>adam krawiec</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375064</th>\n",
       "      <td>t kopf</td>\n",
       "      <td>albrecht klemm</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269746</th>\n",
       "      <td>d a owen</td>\n",
       "      <td>yutaka ookouchi</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76918</th>\n",
       "      <td>l h ryder</td>\n",
       "      <td>subhash rajpoot</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276649</th>\n",
       "      <td>n a obers</td>\n",
       "      <td>yutaka ookouchi</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              candidate_1  \\\n",
       "441906                 m z iofa nuclear physics institute   \n",
       "61177   st a ephane ouvry division de physique th eorique   \n",
       "359242  sergei m kuzenko institut fuer theoretische ph...   \n",
       "422225                       norma manko v c bor v s tnik   \n",
       "397049                             m semenov-tian-shansky   \n",
       "...                                                   ...   \n",
       "388590                                          m khlopov   \n",
       "375064                                             t kopf   \n",
       "269746                                           d a owen   \n",
       "76918                                           l h ryder   \n",
       "276649                                          n a obers   \n",
       "\n",
       "                                             candidate_2  edit_dist  \\\n",
       "441906                 m z iofa nuclear physics intitute          1   \n",
       "61177    st ephane ouvry division de physique th eorique          2   \n",
       "359242  sergei kuzenko institut fuer theoretische physik          2   \n",
       "422225                       norma manko v c bor v stnik          1   \n",
       "397049                          m a semenov-tian-shansky          2   \n",
       "...                                                  ...        ...   \n",
       "388590                                      adam krawiec          9   \n",
       "375064                                    albrecht klemm         11   \n",
       "269746                                   yutaka ookouchi         12   \n",
       "76918                                    subhash rajpoot         12   \n",
       "276649                                   yutaka ookouchi         12   \n",
       "\n",
       "        fuzzy_score  \n",
       "441906         99.0  \n",
       "61177          99.0  \n",
       "359242         99.0  \n",
       "422225         98.0  \n",
       "397049         98.0  \n",
       "...             ...  \n",
       "388590         10.0  \n",
       "375064         10.0  \n",
       "269746          9.0  \n",
       "76918           8.0  \n",
       "276649          8.0  \n",
       "\n",
       "[443659 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn_df.sort_values(by=[\"fuzzy_score\"], ascending=False)[cpn_df[\"fuzzy_score\"]!=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes\n",
    "cpn = cpn_df.merge(unique_authors_df, left_on='candidate_1',right_on='cleaned')[[\"candidate_1\",\"candidate_2\",\"edit_dist\",\"fuzzy_score\",\"index_nr\"]]\n",
    "cpn.rename(columns={\"index_nr\":\"index_nr_c1\"},inplace=True)\n",
    "cpn = cpn.merge(unique_authors_df, left_on='candidate_2',right_on='cleaned')[[\"candidate_1\",\"candidate_2\",\"edit_dist\",\"index_nr_c1\",\"fuzzy_score\",\"index_nr\"]]\n",
    "cpn.rename(columns={\"index_nr\":\"index_nr_c2\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpn['first_letter'] = np.where(cpn[\"candidate_1\"].astype(str).str[0] == cpn[\"candidate_2\"].astype(str).str[0], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 s, sys: 290 ms, total: 30 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Function to find out if first letters of comparable names are within same sounding character range\n",
    "first_letter_jy = []\n",
    "first_letter_ck = []\n",
    "\n",
    "for index, row in cpn.iterrows():\n",
    "    if row[\"candidate_1\"][0] in [\"j\",\"y\"] and row[\"candidate_2\"][0] in [\"j\",\"y\"]:\n",
    "        first_letter_jy.append(True)\n",
    "        first_letter_ck.append(False)\n",
    "    \n",
    "    elif row[\"candidate_1\"][0] in [\"c\",\"k\"] and row[\"candidate_2\"][0] in [\"c\",\"k\"]:\n",
    "        first_letter_jy.append(False)\n",
    "        first_letter_ck.append(True)\n",
    "        \n",
    "    else:\n",
    "        first_letter_jy.append(False)\n",
    "        first_letter_ck.append(False)\n",
    "\n",
    "cpn['first_letter_jy'] = first_letter_jy\n",
    "cpn['first_letter_ck'] = first_letter_ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpn.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliavanoosten/anaconda3/envs/AppliedDS/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "      <th>index_nr_c1</th>\n",
       "      <th>fuzzy_score</th>\n",
       "      <th>index_nr_c2</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>first_letter_jy</th>\n",
       "      <th>first_letter_ck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441734</th>\n",
       "      <td>jerome gauntlett</td>\n",
       "      <td>jerome p gauntlett</td>\n",
       "      <td>2</td>\n",
       "      <td>8047</td>\n",
       "      <td>97.0</td>\n",
       "      <td>15711</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351480</th>\n",
       "      <td>a aghamohammdi</td>\n",
       "      <td>a aghamohammadi</td>\n",
       "      <td>1</td>\n",
       "      <td>3382</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24880</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144319</th>\n",
       "      <td>thomas schuecker</td>\n",
       "      <td>thomas schucker</td>\n",
       "      <td>1</td>\n",
       "      <td>5700</td>\n",
       "      <td>97.0</td>\n",
       "      <td>21538</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>max-planck-institut</td>\n",
       "      <td>max-planck-institute</td>\n",
       "      <td>1</td>\n",
       "      <td>16592</td>\n",
       "      <td>97.0</td>\n",
       "      <td>25364</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379594</th>\n",
       "      <td>paul steinhardt</td>\n",
       "      <td>paul j steinhardt</td>\n",
       "      <td>2</td>\n",
       "      <td>6148</td>\n",
       "      <td>97.0</td>\n",
       "      <td>25148</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393054</th>\n",
       "      <td>pierre bin etruy</td>\n",
       "      <td>pierre binetruy</td>\n",
       "      <td>1</td>\n",
       "      <td>21677</td>\n",
       "      <td>97.0</td>\n",
       "      <td>22058</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396927</th>\n",
       "      <td>yoichro matsumura</td>\n",
       "      <td>yoichiro matsumura</td>\n",
       "      <td>1</td>\n",
       "      <td>6469</td>\n",
       "      <td>97.0</td>\n",
       "      <td>18272</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419951</th>\n",
       "      <td>a polychronakos</td>\n",
       "      <td>a p polychronakos</td>\n",
       "      <td>2</td>\n",
       "      <td>10959</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23294</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46818</th>\n",
       "      <td>daniel freedman</td>\n",
       "      <td>daniel z freedman</td>\n",
       "      <td>2</td>\n",
       "      <td>1306</td>\n",
       "      <td>97.0</td>\n",
       "      <td>21618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311337</th>\n",
       "      <td>tatiana a ivanova</td>\n",
       "      <td>tatiana ivanova</td>\n",
       "      <td>2</td>\n",
       "      <td>3567</td>\n",
       "      <td>97.0</td>\n",
       "      <td>14931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                candidate_1           candidate_2  edit_dist  index_nr_c1  \\\n",
       "441734     jerome gauntlett    jerome p gauntlett          2         8047   \n",
       "351480       a aghamohammdi       a aghamohammadi          1         3382   \n",
       "144319     thomas schuecker       thomas schucker          1         5700   \n",
       "232494  max-planck-institut  max-planck-institute          1        16592   \n",
       "379594      paul steinhardt     paul j steinhardt          2         6148   \n",
       "...                     ...                   ...        ...          ...   \n",
       "393054     pierre bin etruy       pierre binetruy          1        21677   \n",
       "396927    yoichro matsumura    yoichiro matsumura          1         6469   \n",
       "419951      a polychronakos     a p polychronakos          2        10959   \n",
       "46818       daniel freedman     daniel z freedman          2         1306   \n",
       "311337    tatiana a ivanova       tatiana ivanova          2         3567   \n",
       "\n",
       "        fuzzy_score  index_nr_c2  first_letter  first_letter_jy  \\\n",
       "441734         97.0        15711          True             True   \n",
       "351480         97.0        24880          True            False   \n",
       "144319         97.0        21538          True            False   \n",
       "232494         97.0        25364          True            False   \n",
       "379594         97.0        25148          True            False   \n",
       "...             ...          ...           ...              ...   \n",
       "393054         97.0        22058          True            False   \n",
       "396927         97.0        18272          True             True   \n",
       "419951         97.0        23294          True            False   \n",
       "46818          97.0        21618          True            False   \n",
       "311337         97.0        14931          True            False   \n",
       "\n",
       "        first_letter_ck  \n",
       "441734            False  \n",
       "351480            False  \n",
       "144319            False  \n",
       "232494            False  \n",
       "379594            False  \n",
       "...                 ...  \n",
       "393054            False  \n",
       "396927            False  \n",
       "419951            False  \n",
       "46818             False  \n",
       "311337            False  \n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn.sort_values(by=\"fuzzy_score\",ascending=False)[cpn[\"fuzzy_score\"]==97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "      <th>index_nr_c1</th>\n",
       "      <th>fuzzy_score</th>\n",
       "      <th>index_nr_c2</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>first_letter_jy</th>\n",
       "      <th>first_letter_ck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>john w barrett</td>\n",
       "      <td>j audretsch</td>\n",
       "      <td>11</td>\n",
       "      <td>6938</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>j arafune</td>\n",
       "      <td>j audretsch</td>\n",
       "      <td>7</td>\n",
       "      <td>2603</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>j a e carrillo</td>\n",
       "      <td>j audretsch</td>\n",
       "      <td>10</td>\n",
       "      <td>3797</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>j ambjorn nbi</td>\n",
       "      <td>j audretsch</td>\n",
       "      <td>9</td>\n",
       "      <td>7372</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>j ambj o rn</td>\n",
       "      <td>j audretsch</td>\n",
       "      <td>8</td>\n",
       "      <td>8722</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443555</th>\n",
       "      <td>j froehlich</td>\n",
       "      <td>juerg froehlich</td>\n",
       "      <td>4</td>\n",
       "      <td>5764</td>\n",
       "      <td>87.5</td>\n",
       "      <td>14492</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443559</th>\n",
       "      <td>yoav lavi</td>\n",
       "      <td>yoav lederer</td>\n",
       "      <td>6</td>\n",
       "      <td>12386</td>\n",
       "      <td>59.5</td>\n",
       "      <td>16615</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443654</th>\n",
       "      <td>jae-kwan kim</td>\n",
       "      <td>joe kiskis</td>\n",
       "      <td>7</td>\n",
       "      <td>1346</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4761</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443695</th>\n",
       "      <td>yi-yen wu lbnl</td>\n",
       "      <td>yi-yen wu uc berkeley</td>\n",
       "      <td>9</td>\n",
       "      <td>3995</td>\n",
       "      <td>73.5</td>\n",
       "      <td>4484</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443701</th>\n",
       "      <td>jr cbpf</td>\n",
       "      <td>jr ufma</td>\n",
       "      <td>4</td>\n",
       "      <td>917</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23708</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10892 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           candidate_1            candidate_2  edit_dist  index_nr_c1  \\\n",
       "124     john w barrett            j audretsch         11         6938   \n",
       "126          j arafune            j audretsch          7         2603   \n",
       "127     j a e carrillo            j audretsch         10         3797   \n",
       "130      j ambjorn nbi            j audretsch          9         7372   \n",
       "131        j ambj o rn            j audretsch          8         8722   \n",
       "...                ...                    ...        ...          ...   \n",
       "443555     j froehlich        juerg froehlich          4         5764   \n",
       "443559       yoav lavi           yoav lederer          6        12386   \n",
       "443654    jae-kwan kim             joe kiskis          7         1346   \n",
       "443695  yi-yen wu lbnl  yi-yen wu uc berkeley          9         3995   \n",
       "443701         jr cbpf                jr ufma          4          917   \n",
       "\n",
       "        fuzzy_score  index_nr_c2  first_letter  first_letter_jy  \\\n",
       "124            48.0        14304          True             True   \n",
       "126            50.0        14304          True             True   \n",
       "127            40.0        14304          True             True   \n",
       "130            33.0        14304          True             True   \n",
       "131            31.5        14304          True             True   \n",
       "...             ...          ...           ...              ...   \n",
       "443555         87.5        14492          True             True   \n",
       "443559         59.5        16615          True             True   \n",
       "443654         55.0         4761          True             True   \n",
       "443695         73.5         4484          True             True   \n",
       "443701         43.0        23708          True             True   \n",
       "\n",
       "        first_letter_ck  \n",
       "124               False  \n",
       "126               False  \n",
       "127               False  \n",
       "130               False  \n",
       "131               False  \n",
       "...                 ...  \n",
       "443555            False  \n",
       "443559            False  \n",
       "443654            False  \n",
       "443695            False  \n",
       "443701            False  \n",
       "\n",
       "[10892 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn[cpn[\"first_letter_jy\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_75 = cpn[(cpn[\"fuzzy_score\"]>=75) & (cpn[\"first_letter\"] == True)]\n",
    "scores_85 = cpn[(cpn[\"fuzzy_score\"]>=85) & (cpn[\"first_letter\"] == True)]\n",
    "scores_90 = cpn[(cpn[\"fuzzy_score\"]>=90) & (cpn[\"first_letter\"] == True)]\n",
    "scores_100 = cpn[(cpn[\"fuzzy_score\"]==100) & (cpn[\"first_letter\"] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY WITH EDIT DISTANCES\n",
    "scores_1 = cpn[(cpn[\"edit_dist\"]==1) & (cpn[\"first_letter\"] == True)]\n",
    "scores_2 = cpn[(cpn[\"edit_dist\"]<=2) & (cpn[\"first_letter\"] == True)]\n",
    "scores_3 = cpn[(cpn[\"edit_dist\"]<=3) & (cpn[\"first_letter\"] == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_author_sim(unique_authors_df, scores_df, combined):\n",
    "    # combine dataframes\n",
    "    df = pd.DataFrame()\n",
    "    df[\"candidate_1\"] = scores_df[\"candidate_1\"]\n",
    "    df[\"candidate_2\"] = scores_df[\"candidate_2\"]\n",
    "    df[\"index_nr_c1\"] = scores_df[\"index_nr_c1\"]\n",
    "    df[\"index_nr_c2\"] = scores_df[\"index_nr_c2\"]\n",
    "    df[\"edit_dist\"] = scores_df[\"edit_dist\"]\n",
    "    df[\"fuzzy_score\"] = scores_df[\"fuzzy_score\"]\n",
    "    \n",
    "    df = df.merge(unique_authors_df[[\"affiliated_papers\",\"index_nr\"]], left_on = \"index_nr_c1\",right_on = \"index_nr\")\n",
    "    df = df.merge(unique_authors_df[[\"affiliated_papers\",\"index_nr\"]], left_on = \"index_nr_c2\",right_on = \"index_nr\")\n",
    "    df.rename(columns={\"affiliated_papers_x\": \"affiliated_papers_c1\", \"affiliated_papers_y\": \"affiliated_papers_c2\"},inplace=True)\n",
    "    df = df[[\"candidate_2\",\"candidate_1\",\"index_nr_c1\",\"index_nr_c2\",\"affiliated_papers_c1\",\"affiliated_papers_c2\",\"edit_dist\",\"fuzzy_score\"]]\n",
    "    \n",
    "    # find intersecting papers for each candidate pairs\n",
    "    df.dropna(inplace=True)\n",
    "    intersect_papers = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        intersect_papers.append(list(set(row[\"affiliated_papers_c1\"]) & set(row[\"affiliated_papers_c2\"])))\n",
    "    \n",
    "    df[\"intersect_papers\"] = intersect_papers\n",
    "    \n",
    "    # calculate intersection ratio\n",
    "    df['union_papers'] = df[['affiliated_papers_c1', 'affiliated_papers_c2']].values.tolist()\n",
    "    df[\"union_papers\"] = df[\"union_papers\"].apply(lambda x: list(set(flatten_list(x))))\n",
    "    paper_ratio = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            paper_ratio.append(len(row[\"intersect_papers\"])/len(row[\"union_papers\"]))\n",
    "        except:\n",
    "            paper_ratio.append(0)\n",
    "        \n",
    "    df[\"paper_ratio\"] = paper_ratio\n",
    "    \n",
    "    # get co-authors\n",
    "    co_authors_c1 = []\n",
    "    co_authors_c2 = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        co_authors_c1.append(combined[lambda df: df[\"paper\"].isin(row[\"affiliated_papers_c1\"])][\"authors\"].tolist())\n",
    "        co_authors_c2.append(combined[lambda df: df[\"paper\"].isin(row[\"affiliated_papers_c2\"])][\"authors\"].tolist())\n",
    "        \n",
    "    # flatten co_authors and add, get them in universal format first\n",
    "    df[\"co_authors_c1\"] = co_authors_c1\n",
    "    df[\"co_authors_c2\"] = co_authors_c2\n",
    "    df[\"co_authors_c1\"] = df[\"co_authors_c1\"].apply(lambda x: set(flatten_list(x)))\n",
    "    df[\"co_authors_c2\"] = df[\"co_authors_c2\"].apply(lambda x: set(flatten_list(x)))\n",
    "    df[\"co_authors_c1\"] = df[\"co_authors_c1\"].apply(lambda x: list(name(elem) for elem in x))\n",
    "    df[\"co_authors_c2\"] = df[\"co_authors_c2\"].apply(lambda x: list(name(elem) for elem in x))\n",
    "    \n",
    "    \n",
    "    # find intersecting co_authors for each candidate pair\n",
    "    df.dropna(inplace=True)\n",
    "    intersect_authors = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        intersect_authors.append(list(set(row[\"co_authors_c1\"]) & (set(row[\"co_authors_c2\"]))))\n",
    "    \n",
    "    df[\"intersect_authors\"] = intersect_authors\n",
    "    \n",
    "    # calculate intersection ratio\n",
    "    df['union_authors'] = df[['co_authors_c1', 'co_authors_c2']].values.tolist()\n",
    "    df[\"union_authors\"] = df[\"union_authors\"].apply(lambda x: list(set(flatten_list(x))))\n",
    "    \n",
    "    author_ratio = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            author_ratio.append(len(row[\"intersect_authors\"])/len(row[\"union_authors\"]))\n",
    "        except:\n",
    "            author_ratio.append(0)\n",
    "        \n",
    "    df[\"author_ratio\"] = author_ratio\n",
    "    \n",
    "    # get correlations\n",
    "    corr_authors = df[[\"author_ratio\",\"fuzzy_score\"]].corr()\n",
    "    corr_papers = df[[\"paper_ratio\",\"fuzzy_score\"]].corr()\n",
    "    \n",
    "    return(df.sort_values(by=\"author_ratio\",ascending=False),corr_authors,corr_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>edit_dist</th>\n",
       "      <th>index_nr_c1</th>\n",
       "      <th>fuzzy_score</th>\n",
       "      <th>index_nr_c2</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>first_letter_jy</th>\n",
       "      <th>first_letter_ck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>h j w mueller--kirsten</td>\n",
       "      <td>h j w mueller-kirsten</td>\n",
       "      <td>1</td>\n",
       "      <td>8454</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15764</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>juan perez--mercader laeff</td>\n",
       "      <td>juan perez-mercader laeff</td>\n",
       "      <td>1</td>\n",
       "      <td>7898</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18205</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36991</th>\n",
       "      <td>m b silva-neto</td>\n",
       "      <td>m b silva neto</td>\n",
       "      <td>1</td>\n",
       "      <td>15161</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19563</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66192</th>\n",
       "      <td>dieter lust humboldt university</td>\n",
       "      <td>dieter lust humboldt-university</td>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25405</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68509</th>\n",
       "      <td>st-petersburg</td>\n",
       "      <td>st petersburg</td>\n",
       "      <td>1</td>\n",
       "      <td>13456</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22019</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442121</th>\n",
       "      <td>a gonz alez--ruiz</td>\n",
       "      <td>a gonz alez-ruiz</td>\n",
       "      <td>1</td>\n",
       "      <td>5686</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14130</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442279</th>\n",
       "      <td>y h quano</td>\n",
       "      <td>y -h quano</td>\n",
       "      <td>1</td>\n",
       "      <td>9304</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18827</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443072</th>\n",
       "      <td>c-m viallet</td>\n",
       "      <td>c -m viallet</td>\n",
       "      <td>1</td>\n",
       "      <td>6367</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8825</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443204</th>\n",
       "      <td>j c yera</td>\n",
       "      <td>j -c yera</td>\n",
       "      <td>1</td>\n",
       "      <td>3927</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19078</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443626</th>\n",
       "      <td>a gonz alez--ruiz</td>\n",
       "      <td>a gonz alez ruiz</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8425</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            candidate_1                      candidate_2  \\\n",
       "8961             h j w mueller--kirsten            h j w mueller-kirsten   \n",
       "11917        juan perez--mercader laeff        juan perez-mercader laeff   \n",
       "36991                    m b silva-neto                   m b silva neto   \n",
       "66192   dieter lust humboldt university  dieter lust humboldt-university   \n",
       "68509                     st-petersburg                    st petersburg   \n",
       "...                                 ...                              ...   \n",
       "442121                a gonz alez--ruiz                 a gonz alez-ruiz   \n",
       "442279                        y h quano                       y -h quano   \n",
       "443072                      c-m viallet                     c -m viallet   \n",
       "443204                         j c yera                        j -c yera   \n",
       "443626                a gonz alez--ruiz                 a gonz alez ruiz   \n",
       "\n",
       "        edit_dist  index_nr_c1  fuzzy_score  index_nr_c2  first_letter  \\\n",
       "8961            1         8454        100.0        15764          True   \n",
       "11917           1         7898        100.0        18205          True   \n",
       "36991           1        15161        100.0        19563          True   \n",
       "66192           1         2262        100.0        25405          True   \n",
       "68509           1        13456        100.0        22019          True   \n",
       "...           ...          ...          ...          ...           ...   \n",
       "442121          1         5686        100.0        14130          True   \n",
       "442279          1         9304        100.0        18827          True   \n",
       "443072          1         6367        100.0         8825          True   \n",
       "443204          1         3927        100.0        19078          True   \n",
       "443626          2         5686        100.0         8425          True   \n",
       "\n",
       "        first_letter_jy  first_letter_ck  \n",
       "8961              False            False  \n",
       "11917              True            False  \n",
       "36991             False            False  \n",
       "66192             False            False  \n",
       "68509             False            False  \n",
       "...                 ...              ...  \n",
       "442121            False            False  \n",
       "442279             True            False  \n",
       "443072            False             True  \n",
       "443204             True            False  \n",
       "443626            False            False  \n",
       "\n",
       "[70 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply checks\n",
    "scores_100 = co_author_sim(unique_authors_df, scores_100, combined_df)[0]\n",
    "scores_100 = scores_100[(scores_100[\"paper_ratio\"]!=1)]\n",
    "\n",
    "scores_90 = co_author_sim(unique_authors_df, scores_90, combined_df)[0]\n",
    "scores_90 = scores_90[(scores_90[\"paper_ratio\"]!=1)]\n",
    "\n",
    "scores_85 = co_author_sim(unique_authors_df, scores_85, combined_df)[0]\n",
    "scores_85 = scores_85[(scores_85[\"paper_ratio\"]!=1)]\n",
    "\n",
    "scores_75 = co_author_sim(unique_authors_df, scores_75, combined_df)[0]\n",
    "scores_75 = scores_75[(scores_75[\"paper_ratio\"]!=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FuzzyWuzzy Scores\n",
    "scores_75_network = nx.Graph()\n",
    "scores_90_network = nx.Graph()\n",
    "scores_85_network = nx.Graph()\n",
    "scores_100_network = nx.Graph()\n",
    "\n",
    "# scores_75_network.add_nodes_from(list(zip(list(unique_authors_df[\"index_nr\"]),list(unique_authors_df[\"cleaned\"]))))\n",
    "# scores_90_network.add_nodes_from(list(zip(list(unique_authors_df[\"index_nr\"]),list(unique_authors_df[\"cleaned\"]))))\n",
    "# scores_85_network.add_nodes_from(list(zip(list(unique_authors_df[\"index_nr\"]),list(unique_authors_df[\"cleaned\"]))))\n",
    "# scores_100_network.add_nodes_from(list(zip(list(unique_authors_df[\"index_nr\"]),list(unique_authors_df[\"cleaned\"]))))\n",
    "\n",
    "scores_75_network.add_nodes_from(list(unique_authors_df[\"index_nr\"]))\n",
    "scores_90_network.add_nodes_from(list(unique_authors_df[\"index_nr\"]))\n",
    "scores_85_network.add_nodes_from(list(unique_authors_df[\"index_nr\"]))\n",
    "scores_100_network.add_nodes_from(list(unique_authors_df[\"index_nr\"]))\n",
    "\n",
    "\n",
    "edges_75 = list(zip(scores_75[\"index_nr_c1\"], scores_75[\"index_nr_c2\"]))\n",
    "edges_90 = list(zip(scores_90[\"index_nr_c1\"], scores_90[\"index_nr_c2\"]))\n",
    "edges_85 = list(zip(scores_85[\"index_nr_c1\"], scores_85[\"index_nr_c2\"]))\n",
    "edges_100 = list(zip(scores_100[\"index_nr_c1\"], scores_100[\"index_nr_c2\"]))\n",
    "\n",
    "\n",
    "scores_75_network.add_edges_from(edges_75)\n",
    "scores_90_network.add_edges_from(edges_90)\n",
    "scores_85_network.add_edges_from(edges_85)\n",
    "scores_100_network.add_edges_from(edges_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use clean_authors function on this dataset, should have done that way before defining unique_authors but here we are\n",
    "combined_df[\"authors\"] = combined_df[\"authors\"].apply(lambda x: clean_authors(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.5512048192771084 0.5201834862385321 0.5279144121987212\n"
     ]
    }
   ],
   "source": [
    "print(nx.transitivity(scores_100_network),nx.transitivity(scores_90_network), nx.transitivity(scores_85_network), nx.transitivity(scores_75_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 1188 2324 5582\n"
     ]
    }
   ],
   "source": [
    "print(scores_100_network.number_of_edges(), scores_90_network.number_of_edges(), scores_85_network.number_of_edges(), scores_75_network.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(scores_100_network,\"step1_100.csv\", delimiter=',')\n",
    "nx.write_edgelist(scores_90_network,\"step1_90.csv\", delimiter=',')\n",
    "nx.write_edgelist(scores_85_network,\"step1_85.csv\", delimiter=',')\n",
    "nx.write_edgelist(scores_75_network,\"step1_75.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14250 14250 14250 14250\n"
     ]
    }
   ],
   "source": [
    "print(scores_100_network.number_of_nodes(), scores_90_network.number_of_nodes(), scores_85_network.number_of_nodes(), scores_75_network.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of co-authors and shared papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find pairs that are unclosed!! \n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# Define node_in_open_triangle()\n",
    "def node_in_open_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Checks whether pairs of neighbors of node `n` in graph `G` are in an 'open triangle' relationship with node `n`.\n",
    "    \"\"\"\n",
    "    in_open_triangle = False\n",
    "    open_triangle = []\n",
    "\n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "\n",
    "        # Check if n1 and n2 do NOT have an edge between them\n",
    "        if not G.has_edge(n1, n2):\n",
    "\n",
    "            in_open_triangle = True\n",
    "            open_triangle.append((n1,n2))\n",
    "            \n",
    "            break\n",
    "\n",
    "    return in_open_triangle,open_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sim_unclosed_triangles(unique_authors_df, unclosed_triangles, combined):\n",
    "    df = unclosed_triangles\n",
    "    df = df.merge(unique_authors_df[[\"affiliated_papers\",\"index_nr\",\"cleaned\"]], left_on = \"index_nr_c1\",right_on = \"index_nr\")\n",
    "    df = df.merge(unique_authors_df[[\"affiliated_papers\",\"index_nr\",\"cleaned\"]], left_on = \"index_nr_c2\",right_on = \"index_nr\")\n",
    "    df.rename(columns={\"affiliated_papers_x\": \"affiliated_papers_c1\", \"affiliated_papers_y\": \"affiliated_papers_c2\", \"cleaned_x\":\"name_c1\",\"cleaned_y\":\"name_c2\"},inplace=True)\n",
    "    df = df[[\"index_nr_c1\",\"index_nr_c2\",\"affiliated_papers_c1\",\"affiliated_papers_c2\",\"name_c1\",\"name_c2\"]]\n",
    "    \n",
    "    # find intersecting papers for each candidate pairs\n",
    "    df.dropna(inplace=True)\n",
    "    intersect_papers = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        intersect_papers.append(list(set(row[\"affiliated_papers_c1\"]) & set(row[\"affiliated_papers_c2\"])))\n",
    "    \n",
    "    df[\"intersect_papers\"] = intersect_papers\n",
    "    \n",
    "    # calculate intersection ratio\n",
    "    df['union_papers'] = df[['affiliated_papers_c1', 'affiliated_papers_c2']].values.tolist()\n",
    "    df[\"union_papers\"] = df[\"union_papers\"].apply(lambda x: list(set(flatten_list(x))))\n",
    "    paper_ratio = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            paper_ratio.append(len(row[\"intersect_papers\"])/len(row[\"union_papers\"]))\n",
    "        except:\n",
    "            paper_ratio.append(0)\n",
    "        \n",
    "    df[\"paper_ratio\"] = paper_ratio\n",
    "    \n",
    "    # get co-authors\n",
    "    co_authors_c1 = []\n",
    "    co_authors_c2 = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        co_authors_c1.append(combined[lambda df: df[\"paper\"].isin(row[\"affiliated_papers_c1\"])][\"authors\"].tolist())\n",
    "        co_authors_c2.append(combined[lambda df: df[\"paper\"].isin(row[\"affiliated_papers_c2\"])][\"authors\"].tolist())\n",
    "    \n",
    "    \n",
    "    # flatten co_authors and add, get them in universal format first\n",
    "    df[\"co_authors_c1\"] = co_authors_c1\n",
    "    df[\"co_authors_c2\"] = co_authors_c2\n",
    "    df[\"co_authors_c1\"] = df[\"co_authors_c1\"].apply(lambda x: set(flatten_list(x)))\n",
    "    df[\"co_authors_c2\"] = df[\"co_authors_c2\"].apply(lambda x: set(flatten_list(x)))\n",
    "    df[\"co_authors_c1\"] = df[\"co_authors_c1\"].apply(lambda x: list(name(elem) for elem in x))\n",
    "    df[\"co_authors_c2\"] = df[\"co_authors_c2\"].apply(lambda x: list(name(elem) for elem in x))\n",
    "    \n",
    "    \n",
    "    # find intersecting co_authors for each candidate pair\n",
    "    df.dropna(inplace=True)\n",
    "    intersect_authors = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        intersect_authors.append(list(set(row[\"co_authors_c1\"]) & (set(row[\"co_authors_c2\"]))))\n",
    "    \n",
    "    df[\"intersect_authors\"] = intersect_authors\n",
    "    \n",
    "    # calculate intersection ratio\n",
    "    df['union_authors'] = df[['co_authors_c1', 'co_authors_c2']].values.tolist()\n",
    "    df[\"union_authors\"] = df[\"union_authors\"].apply(lambda x: list(set(flatten_list(x))))\n",
    "    \n",
    "    author_ratio = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            author_ratio.append(len(row[\"intersect_authors\"])/len(row[\"union_authors\"]))\n",
    "        except:\n",
    "            author_ratio.append(0)\n",
    "        \n",
    "    df[\"author_ratio\"] = author_ratio\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Compute the number of open triangles in scores_100\n",
    "num_open_triangles = 0\n",
    "\n",
    "# Iterate over all the nodes in T\n",
    "for n in scores_100_network.nodes():\n",
    "\n",
    "    # Check if the current node is in an open triangle\n",
    "    if node_in_open_triangle(scores_100_network, n)[0]:\n",
    "\n",
    "        # Increment num_open_triangles\n",
    "        num_open_triangles += 1\n",
    "\n",
    "print(num_open_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the unclosed triangles\n",
    "def find_unclosed(scores_network):\n",
    "    unclosed_triangles = {}\n",
    "\n",
    "    for n in scores_network.nodes():\n",
    "        if node_in_open_triangle(scores_network, n)[1]:\n",
    "            unclosed_triangles[n] = node_in_open_triangle(scores_network, n)[1]\n",
    "    return unclosed_triangles\n",
    "\n",
    "def create_unclosed_df(unclosed_triangles):\n",
    "    unclosed_triangles = pd.DataFrame(unclosed_triangles).T\n",
    "    unclosed_triangles.rename(columns={0:\"pair\"},inplace=True)\n",
    "    unclosed_triangles[['index_nr_c1', 'index_nr_c2']] = pd.DataFrame(unclosed_triangles['pair'].tolist(), index=unclosed_triangles.index)\n",
    "    unclosed_triangles.reset_index(inplace=True)\n",
    "    unclosed_triangles.rename(columns={\"index\":\"bridge_node\"},inplace=True)\n",
    "    return unclosed_triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new \"sameas\" edges based on paper and author ratio\n",
    "def get_new_edges(unclosed_triangles_df):\n",
    "    new = unclosed_triangles_df[(unclosed_triangles_df[\"paper_ratio\"]== 0.0) & (unclosed_triangles_df[\"author_ratio\"]>= 0.20)]\n",
    "    new_edges = set(list(zip(new[\"index_nr_c1\"], new[\"index_nr_c2\"])))\n",
    "    return new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 8.26 ms, total: 232 ms\n",
      "Wall time: 276 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#unclosed_triangles_100 = create_unclosed_df(find_unclosed(scores_100_network))\n",
    "unclosed_triangles_90 = create_unclosed_df(find_unclosed(scores_90_network))\n",
    "unclosed_triangles_85 =  create_unclosed_df(find_unclosed(scores_85_network))\n",
    "unclosed_triangles_75 = create_unclosed_df(find_unclosed(scores_75_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.9375 0.5111111111111111 0.467674661105318 0.5888904166093771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # for the 100 threshold\n",
    "# edges = get_new_edges(sim_unclosed_triangles(unique_authors_df, unclosed_triangles_100, combined_df))\n",
    "# scores_100_network.add_edges_from(edges)\n",
    "# nx.transitivity(scores_100_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 668 ms, sys: 43.6 ms, total: 712 ms\n",
      "Wall time: 804 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6147540983606558"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# for the 90 threshold\n",
    "edges = get_new_edges(sim_unclosed_triangles(unique_authors_df, unclosed_triangles_90, combined_df))\n",
    "scores_90_network.add_edges_from(edges)\n",
    "nx.transitivity(scores_90_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 29.1 ms, total: 1.94 s\n",
      "Wall time: 2.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6320830007980845"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# for the 85 threshold\n",
    "edges = get_new_edges(sim_unclosed_triangles(unique_authors_df, unclosed_triangles_85, combined_df))\n",
    "scores_85_network.add_edges_from(edges)\n",
    "nx.transitivity(scores_85_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.72 s, sys: 80 ms, total: 5.8 s\n",
      "Wall time: 6.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5421513370907782"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# for the 75 threshold\n",
    "edges = get_new_edges(sim_unclosed_triangles(unique_authors_df, unclosed_triangles_75, combined_df))\n",
    "scores_75_network.add_edges_from(edges)\n",
    "nx.transitivity(scores_75_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 1201 2385 5639\n"
     ]
    }
   ],
   "source": [
    "print(scores_100_network.number_of_edges(), scores_90_network.number_of_edges(), scores_85_network.number_of_edges(), scores_75_network.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14250 14250 14250 14250\n"
     ]
    }
   ],
   "source": [
    "print(scores_100_network.number_of_nodes(), scores_90_network.number_of_nodes(), scores_85_network.number_of_nodes(), scores_75_network.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14190 13117 12109 9723\n"
     ]
    }
   ],
   "source": [
    "print(nx.number_connected_components(scores_100_network), nx.number_connected_components(scores_90_network), nx.number_connected_components(scores_85_network),nx.number_connected_components(scores_75_network),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping from ID to author name\n",
    "mapping = unique_authors_df[[\"cleaned\",\"index_nr\"]].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = mapping[\"cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_100_names_network = nx.relabel_nodes(scores_100_network, mapping, copy=True)\n",
    "scores_90_names_network = nx.relabel_nodes(scores_90_network, mapping, copy=True)\n",
    "scores_85_names_network = nx.relabel_nodes(scores_85_network, mapping, copy=True)\n",
    "scores_75_names_network = nx.relabel_nodes(scores_75_network, mapping, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(scores_100_names_network,\"final_100_names.csv\", delimiter=',')\n",
    "# nx.write_edgelist(scores_90_names_network,\"final_90_names.csv\", delimiter=',')\n",
    "# nx.write_edgelist(scores_85_names_network,\"final_85_names.csv\", delimiter=',')\n",
    "# nx.write_edgelist(scores_75_names_network,\"final_75_names.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(scores_100_network,\"final_100.csv\")\n",
    "# nx.write_edgelist(scores_90_network,\"final_90.csv\")\n",
    "# nx.write_edgelist(scores_85_network,\"final_85.csv\")\n",
    "# nx.write_edgelist(scores_75_network,\"final_75.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS W1:\n",
    "- Include co-authorship? How?\n",
    "- Include year?\n",
    "- Use NLP?\n",
    "- Creating all possible pairs is a big list, problem? --> Efficiency?\n",
    "  - Remove pairs without same first letter (What if someone is stated by last name only?)\n",
    "- How to solve weird author format/filter out University names e.g.:\n",
    "  Authors: J.C. da Silva (1,2), F.C. Khanna (3,4), A. Matos Neto (1), and A.E.\n",
    "  Santana (1,3) ((1) Instituto de Fisica, Universidade Federal da Bahia, Campus\n",
    "  de Ondina, Salvador, Bahia, Brasil; (2) Centro Federal de Educacao\n",
    "  Tecnologica da Bahia, Salvador, Bahia, Brasil; (3) Physics Department,\n",
    "  Theoretical Physics Institute, University of Alberta, Edmonton, Alberta,\n",
    "  Canada; (4) TRIUMF, Westbrook mall, Vancouver, British Columbia, Canada)\n",
    "- Found multiple ER methods:\n",
    "    - Dedupe (requires some user-labeling)\n",
    "    - Should I use simple string similarity measures? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES/TO DO W1:\n",
    "- Osiris case: Second examiner is Hakim Qahtan, Vahid is day supervisor\n",
    "- Create networks using authors on the same publications\n",
    "- Pair-wise comparison: Levensteihn/edit distance, Hard code with initials/first or second name etc --> (Jon Snow and Jay Snow) = Code my own rule using domain knowledge.\n",
    "- Soundex (if two names sound alike)\n",
    "- Possibly try extra libraries and compare with Levensteihn scores. Error analysis on libraries and what can we do to improve? \n",
    "\n",
    "==> COMPUTE OVERALL SCORE AND SCORE PAIRS\n",
    "\n",
    "- Network of similarity of the names (check also transitivity of this network). \n",
    "- Clustering/community analysis to determine if triangle of 3 authors are the same in similarity network (A is similar to B and B is similar to C, is A = B = C the same? Check if in same cluster or community)\n",
    "- If they are NOT triangles, but similar based on scores --> further research\n",
    "\n",
    "Later on:\n",
    "- Year matters? Someone married and name is changed/affiliation. You expect that co-author similarity is closer in the same year than in two years that are five years apart. Relevance of co-authorship probably fades over time (take into account).\n",
    "- Include year (compare to earlier publications, how to keep track of these entities over time, map new occurences to earlier resolved entities): only when the data is very clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS W2:\n",
    "- All possible pairs = impossible to work with! --> make more logical pairs: \n",
    "\n",
    "### NOTES/TO DO W2:\n",
    "- Scalability issue\n",
    "- Make alphabetic groups and compare pair-wise the authors (a.text, b.text, c.text)\n",
    "- Look at hashing options? \n",
    "- Reduce scalability issue: n-gram indexing (Lucene), 2 or 3 gram, index the authors then query the most similar, then compare those.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES/TO DO MEETING 3:\n",
    "- K shingles on authors and SKIP(on paper abstracts) —> First stick to resolving authors\n",
    "- Naieve function takes too long —> use LSH to compare big amount of documents\n",
    "- LSH and then compare using other methods\n",
    "- Decrease more if fine-tuning parameters/ shingles .. (I want to decrease false negatives)\n",
    "- Keep the indexes to see if duplicates or within the code\n",
    "- Find false positive but by similarity of abstracts they are dissimilar --> show this \n",
    "- NO LONGER USE LUCENE\n",
    "\n",
    "\n",
    "- If you weaken the assumption about what SameAs means, the more likely you will get unclosed triangles\n",
    "- Make sure that it is author names/listed author bc. we have not resolved it into a person yet\n",
    "- Summary: first do the scoring, quantify inconsistencies (how often unclosed triangles)\n",
    "- Find sweet spot between weakening enough to find misspellings but not so much that you are bringing too much noise\n",
    "- We are missing a ground truth, no accuracy is possible\n",
    "- Function of similarity is now edit distance --> try to extend this/use different matters, then decide on a threshold, moving the threshold creates a denser or less dense graph --> count the unclosed triangles (inverse of transitivity). If you increase threshold, transitivy will go down.\n",
    "- Transitivity approximation measures or just transitivity\n",
    "- The lower the transitivity the more inconsistencies you have\n",
    "- Amount of SameAs edges are controlled with similarities\n",
    "- Explore solutions of entity resolution based on name similarity --> investigate how many inconsistencies we have using only string similarity --> then you know how hard the problem is/scale of the problem --> find further solutions (e.g. similarity between co-authors).\n",
    "- First we have similarity based on function (e.g. edit distances), the inconsistencies that still remain (transitivity can get better) can be solved with community similarity/similarity of co-author. (Can also be future work)\n",
    "- Threshold is also determined by hardware limitations (as soon as the graph is too dense to manage = also in bad threshold territory) + ALSO an optimization problem but we are not iterating to optimize --> just pick a few thresholds, optimization problem in future work\n",
    "- Make graphs with different thresholds\n",
    "\n",
    "Literature:\n",
    "- Entity Resolution\n",
    "    - General\n",
    "    - In this context\n",
    "- Local Sensitive Hashing —> with example of names (output)\n",
    "- Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES/TO DO MEETING 4:\n",
    "- How many compononents are there in the network? (subgraphs that you can take out without breaking edges with > 2 nodes). Gives an impression of how big the problem is. How big are these components? If the components covers a lot of entities, threshold is not enough. LOOK AT THE EXAMPLES, EXTRACT EXAMPLES, SEARCH FOR CASES\n",
    "- Mention authors are a set, they are not occurences --> is it a good thing? Try to detect individuals that have the same name = corner case --> limitation because that is not dealt with. Brings an error but is alright. --> If you take more fields instead of just physics this has to be dealt with. \n",
    "- Report for each threshold the transitivity and component and show an image. \n",
    "- In the ideal situation, the transitivity is 1\n",
    "- Make a new scoring system for the similarity of co-authors and add edges if they are similar --> goal to increase transitivity\n",
    "    - For each of the authors add a set of co-authors (all the papers where the author occurs), you then compare the co-authors for the authors you want to compare and decide upon a threshold for that --> add an edge if they are similar. Explain that they are not as strong as the string name. \n",
    "    - For each pair of nodes we put the string similarity and author similarity and get then get the correlation to determine the reliability of co-author similarity --> this dataset does not have affiliations therefore this is a way aka no 100% solution possible\n",
    "    - I am taking the step to find the solution and to determine the scale of the problem\n",
    "- Clean the names before I put them in a set --> mention that cleaning removes noise and setting assumes that they are the same person without the noise. + USE STRIP()\n",
    "- describe REALLY well what my measure is doing \n",
    "- Check my indexes! \n",
    "- Output a lot of things, components and ANALYZE them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE\n",
    "- Added a check whether first letter is the same, as the chance that someone misspells the first letter seems negligable (a jansen and c jansen are probably not the same person) --> Discuss in limitations, however Yuliya en Julia are common misspellings including the first letter.. --> discuss\n",
    "- strip in the beginning\n",
    "- Strings that are the same after cleaning are assumed to be pointing towards the same entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "- Make graphs for pair candidates and compare co-authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Thesis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
